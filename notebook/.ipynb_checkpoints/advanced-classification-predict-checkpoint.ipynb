{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0034c475-0962-4dcc-934f-049f92c09cb3",
   "metadata": {},
   "source": [
    "# ADVANCED CLASSIFICATION PREDICT\n",
    "#### By Dawie Loots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12042635-3289-40ca-82f7-56c93dac89b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Honour Code\n",
    "\n",
    "I, Dawie Loots, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20841b8a-2fde-431a-9590-7047a4b486fc",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Predict overview</a>\n",
    "\n",
    "<a href=#two>2. Importing packages</a>\n",
    "\n",
    "<a href=#three>3. Loading the data</a>\n",
    "\n",
    "<a href=#four>4. Data Preprocessing</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis</a>\n",
    "\n",
    "<a href=#six>6. Modeling</a>\n",
    "\n",
    "<a href=#seven>7. Model performance evaluation</a>\n",
    "\n",
    "<a href=#eight>8. Model analysis and conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e51577-c2e5-46cd-84bf-c442505f77a5",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "### 1. Predict overview\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "With this context, EA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabfd0c-c251-4974-8b2a-3d768ce46ed5",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "### 2. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "bad7e9a6-467d-45f7-9231-da6134ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import chardet # To provide a best estimate of the encoding that was used in the text data\n",
    "import io # For string operations\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import re\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "PARAMETER_CONSTANT = 42  # This is the seed value for random number generation\n",
    "# Vectorizer constants\n",
    "MAX_DF = 0.5\n",
    "MIN_DF = 2\n",
    "NGRAM_RANGE = (1,1)\n",
    "MAX_FEATURES = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3762b8e-2add-425f-8678-9dcb6f373fcc",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "### 3. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "76838241-36bb-4953-bbb9-0d0dbd5e44e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          1   \n",
       "1          1   \n",
       "2          2   \n",
       "3          1   \n",
       "4          1   \n",
       "\n",
       "                                                                                                                                        message  \\\n",
       "0  PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable   \n",
       "1                                                                                It's not like we lack evidence of anthropogenic global warming   \n",
       "2  RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…   \n",
       "3                                           #TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD   \n",
       "4                    RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight   \n",
       "\n",
       "   tweetid  \n",
       "0   625221  \n",
       "1   126103  \n",
       "2   698562  \n",
       "3   573736  \n",
       "4   466954  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('G:/My Drive/Professionele ontwikkeling/Data Science/Explore Data Science Course/Sprint 6_Advanced Classification/Predict/advanced-classification-predict/data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d5c80fe6-a9f0-4c8b-a5bd-63f35f2aa847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6131b-fd90-4cce-8b01-acb12fb175af",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "### 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e004d5b-c9f3-4581-a49d-027009259959",
   "metadata": {},
   "source": [
    "Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a70b03ae-824c-42f0-907a-d9e8327dc16b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2126f41-6fc6-4aee-a1ee-12e6e7b54d86",
   "metadata": {},
   "source": [
    "There is no missing data, so let's proceed by checking for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "5efdf0e3-5f0f-4394-9828-521f736c0e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count = df_train['sentiment'].value_counts()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1b6f-ec7c-470a-9d79-ff95cdcf3df1",
   "metadata": {},
   "source": [
    "Seems like most of the tweets were for class 1 (supporting the belief of man-made changes)\n",
    "Let's divide the total 15,819 tweets by 4, to get +- 3,955 per class.  We will need to upsamle classes 0, -1 and 2, and downsample class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f16beeed-2167-42ce-92c2-be317a239918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3954\n",
       "-1    3954\n",
       " 0    3954\n",
       " 2    3954\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_min1 = df_train[df_train['sentiment']==-1]\n",
    "class_0 = df_train[df_train['sentiment']==0]\n",
    "class_1 = df_train[df_train['sentiment']==1]\n",
    "class_2 = df_train[df_train['sentiment']==2]\n",
    "balance = len(df_train) // 4 # The number of samples that will result in class balance\n",
    "df_train_class1_resampled = resample(class_1,\n",
    "                            replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "df_train_classmin1_resampled = resample(class_min1,\n",
    "                            replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "df_train_class0_resampled = resample(class_0,\n",
    "                            replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "df_train_class2_resampled = resample(class_2,\n",
    "                            replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True) # Reset index before upsampling\n",
    "df_train = pd.concat([df_train_class1_resampled, df_train_classmin1_resampled, \n",
    "                                df_train_class0_resampled, df_train_class2_resampled])\n",
    "df_train.set_index(df_train.index, inplace=True) # Set the default integer index as the new index after upsampling\n",
    "\n",
    "# Check new class counts\n",
    "df_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b6a1c-d625-4153-87b0-cb821c6d09c7",
   "metadata": {},
   "source": [
    "Now that we have class balance, let's proceed with the following steps to convert text into numerical values, so that it can be used for this classification task:\n",
    "\n",
    "- Removing noise (such as web-urls)\n",
    "- Removing punctuation\n",
    "- Tokenization\n",
    "- Removal of stop words\n",
    "- Lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6ad8fee8-859c-4382-9c96-21a61c44d114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>977844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>441956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>978938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>587737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>804767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "11729          1   \n",
       "8308           1   \n",
       "7159           1   \n",
       "5644           1   \n",
       "6732           1   \n",
       "\n",
       "                                                                                                                                                  message  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "       tweetid  \n",
       "11729   977844  \n",
       "8308    441956  \n",
       "7159    978938  \n",
       "5644    587737  \n",
       "6732    804767  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove noise (all hyperlinks)\n",
    "\n",
    "def remove_noise(df):\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'   # Find all hyperlinks\n",
    "    subs_url = r''\n",
    "    df['message'] = df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "    return df\n",
    "\n",
    "remove_noise(df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "bd6cfba5-dfe3-4d55-8051-70dab081df9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Greenpeace: Sad :( Animals and birds which migrate around the world are struggling to adapt to climate change…</td>\n",
       "      <td>909808</td>\n",
       "      <td>RT @Greenpeace: Sad frowning_face_emoticon Animals and birds which migrate around the world are struggling to adapt to climate change…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>1</td>\n",
       "      <td>@timesofindia why do fishermen always fish much beyond limits to catch fish? Must be global warming effect that has less fish :(</td>\n",
       "      <td>855852</td>\n",
       "      <td>@timesofindia why do fishermen always fish much beyond limits to catch fish? Must be global warming effect that has less fish frowning_face_emoticon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @savitriyaca: a must watch, cause climate change is here! :((( Before the Flood - Full Movie | National Geographic Ã¢â‚¬Â¦</td>\n",
       "      <td>891447</td>\n",
       "      <td>RT @savitriyaca: a must watch, cause climate change is here! frowning_face_emoticon(( Before the Flood - Full Movie | National Geographic Ã¢â‚¬Â¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11203</th>\n",
       "      <td>1</td>\n",
       "      <td>@trees_r_cool animal agriculture is the main contributor to climate change :( please watch cowspiracy you'll see the truth!!</td>\n",
       "      <td>164712</td>\n",
       "      <td>@trees_r_cool animal agriculture is the main contributor to climate change frowning_face_emoticon please watch cowspiracy you'll see the truth!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15225</th>\n",
       "      <td>1</td>\n",
       "      <td>@KamalaHarris Start with a Pareto of biggest contributors to climate change:(1) China, (2) Hollywood Trains, Plains, Automobiles, and Yachts</td>\n",
       "      <td>307036</td>\n",
       "      <td>@KamalaHarris Start with a Pareto of biggest contributors to climate changefrowning_face_emoticon1) China, (2) Hollywood Trains, Plains, Automobiles, and Yachts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1</td>\n",
       "      <td>Whenever it randomly snows like this I get v worried about global warming and the poor polar bears :((</td>\n",
       "      <td>166148</td>\n",
       "      <td>Whenever it randomly snows like this I get v worried about global warming and the poor polar bears frowning_face_emoticon(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>0</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens :(</td>\n",
       "      <td>152968</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens frowning_face_emoticon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>0</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens :(</td>\n",
       "      <td>152968</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens frowning_face_emoticon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "2549           1   \n",
       "4687           1   \n",
       "11386          1   \n",
       "11203          1   \n",
       "15225          1   \n",
       "1038           1   \n",
       "5200           0   \n",
       "5200           0   \n",
       "\n",
       "                                                                                                                                            message  \\\n",
       "2549                             RT @Greenpeace: Sad :( Animals and birds which migrate around the world are struggling to adapt to climate change…   \n",
       "4687               @timesofindia why do fishermen always fish much beyond limits to catch fish? Must be global warming effect that has less fish :(   \n",
       "11386                 RT @savitriyaca: a must watch, cause climate change is here! :((( Before the Flood - Full Movie | National Geographic Ã¢â‚¬Â¦   \n",
       "11203                  @trees_r_cool animal agriculture is the main contributor to climate change :( please watch cowspiracy you'll see the truth!!   \n",
       "15225  @KamalaHarris Start with a Pareto of biggest contributors to climate change:(1) China, (2) Hollywood Trains, Plains, Automobiles, and Yachts   \n",
       "1038                                         Whenever it randomly snows like this I get v worried about global warming and the poor polar bears :((   \n",
       "5200                             EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens :(   \n",
       "5200                             EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens :(   \n",
       "\n",
       "       tweetid  \\\n",
       "2549    909808   \n",
       "4687    855852   \n",
       "11386   891447   \n",
       "11203   164712   \n",
       "15225   307036   \n",
       "1038    166148   \n",
       "5200    152968   \n",
       "5200    152968   \n",
       "\n",
       "                                                                                                                                                 message_encoded_emojis  \n",
       "2549                             RT @Greenpeace: Sad frowning_face_emoticon Animals and birds which migrate around the world are struggling to adapt to climate change…  \n",
       "4687               @timesofindia why do fishermen always fish much beyond limits to catch fish? Must be global warming effect that has less fish frowning_face_emoticon  \n",
       "11386                 RT @savitriyaca: a must watch, cause climate change is here! frowning_face_emoticon(( Before the Flood - Full Movie | National Geographic Ã¢â‚¬Â¦  \n",
       "11203                  @trees_r_cool animal agriculture is the main contributor to climate change frowning_face_emoticon please watch cowspiracy you'll see the truth!!  \n",
       "15225  @KamalaHarris Start with a Pareto of biggest contributors to climate changefrowning_face_emoticon1) China, (2) Hollywood Trains, Plains, Automobiles, and Yachts  \n",
       "1038                                         Whenever it randomly snows like this I get v worried about global warming and the poor polar bears frowning_face_emoticon(  \n",
       "5200                             EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens frowning_face_emoticon  \n",
       "5200                             EPA head Scott Pruitt denies that carbon dioxide causes global warming \\nChok uden overraskelse: Faktaresistens frowning_face_emoticon  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle emoticons\n",
    "def process_emoticons(df):\n",
    "    emoticon_dictionary = {':\\)': 'smiley_face_emoticon',\n",
    "                           ':\\(': 'frowning_face_emoticon',\n",
    "                           ':D': 'grinning_face_emoticon',\n",
    "                           ':P': 'sticking_out_tongue_emoticon',\n",
    "                           ';\\)': 'winking_face_emoticon',\n",
    "                           ':o': 'surprised_face_emoticon',\n",
    "                           ':\\|': 'neutral_face_emoticon',\n",
    "                           ':\\'\\)': 'tears_of_joy_emoticon',\n",
    "                           ':\\'\\(': 'crying_face_emoticon'}\n",
    "\n",
    "    df['message_encoded_emojis'] = df['message'].replace(emoticon_dictionary, regex=True)\n",
    "    return df\n",
    "\n",
    "process_emoticons(df_train)\n",
    "# Check if it was correctly \n",
    "emoji_rows = df_train[df_train['message'].str.contains(':\\(')]\n",
    "emoji_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9402beb4-2117-4d0d-b77c-4b6e2ab4cb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "11729          1   \n",
       "8308           1   \n",
       "7159           1   \n",
       "5644           1   \n",
       "6732           1   \n",
       "\n",
       "                                                                                                                                                  message  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "       tweetid  \\\n",
       "11729   977844   \n",
       "8308    441956   \n",
       "7159    978938   \n",
       "5644    587737   \n",
       "6732    804767   \n",
       "\n",
       "                                                                                                                                   message_encoded_emojis  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "                                                                                                                                         message_clean  \n",
       "11729                    RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…  \n",
       "8308                                      YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA  \n",
       "7159                                          RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research   \n",
       "5644                                                       RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange  \n",
       "6732   RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation and expand all contracted words\n",
    "def remove_punctuation(message):\n",
    "    contractions = {\"'t\": \" not\",\"'s\": \" is\",\"'re\": \" are\",\"'ll\": \" will\", \"'m\": \" am\"}\n",
    "    pattern = re.compile(r\"\\b(\" + \"|\".join(re.escape(key) for key in contractions.keys()) + r\")\\b\")\n",
    "    message = re.sub(r\"n't\\b\", \" not\", message) # Replace \"n't\" with \" not\"\n",
    "    message = pattern.sub(lambda match: contractions[match.group(0)], message) # Replace all other contractions except for \"n't\"\n",
    "    return ''.join([l for l in message if l not in string.punctuation])\n",
    "\n",
    "df_train['message_clean'] = df_train['message_encoded_emojis'].apply(remove_punctuation)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "23b14d0b-108c-4e62-b980-d6978c6b2e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…</td>\n",
       "      <td>[RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12292</th>\n",
       "      <td>2</td>\n",
       "      <td>Video: Statoil produces climate change 'roadmap' - News for the Oil and Gas Sector</td>\n",
       "      <td>633554</td>\n",
       "      <td>Video: Statoil produces climate change 'roadmap' - News for the Oil and Gas Sector</td>\n",
       "      <td>Video Statoil produces climate change roadmap  News for the Oil and Gas Sector</td>\n",
       "      <td>[Video, Statoil, produces, climate, change, roadmap, News, for, the, Oil, and, Gas, Sector]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15209</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @Reuters: In rare move, China criticizes Trump plan to exit climate change pact</td>\n",
       "      <td>724243</td>\n",
       "      <td>RT @Reuters: In rare move, China criticizes Trump plan to exit climate change pact</td>\n",
       "      <td>RT Reuters In rare move China criticizes Trump plan to exit climate change pact</td>\n",
       "      <td>[RT, Reuters, In, rare, move, China, criticizes, Trump, plan, to, exit, climate, change, pact]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @DonaldMacDona18: Global climate change battles being won in court  @IIGCCNews #climatechange #carbonbubble #COP2…</td>\n",
       "      <td>878987</td>\n",
       "      <td>RT @DonaldMacDona18: Global climate change battles being won in court  @IIGCCNews #climatechange #carbonbubble #COP2…</td>\n",
       "      <td>RT DonaldMacDona18 Global climate change battles being won in court  IIGCCNews climatechange carbonbubble COP2…</td>\n",
       "      <td>[RT, DonaldMacDona, 18, Global, climate, change, battles, being, won, in, court, IIGCCNews, climatechange, carbonbubble, COP, 2, …]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @BBCBreaking: UK government signs Paris Agreement, world's first comprehensive treaty on tackling climate change Ã¢â‚¬Â¦</td>\n",
       "      <td>151024</td>\n",
       "      <td>RT @BBCBreaking: UK government signs Paris Agreement, world's first comprehensive treaty on tackling climate change Ã¢â‚¬Â¦</td>\n",
       "      <td>RT BBCBreaking UK government signs Paris Agreement world is first comprehensive treaty on tackling climate change Ã¢â‚¬Â¦</td>\n",
       "      <td>[RT, BBCBreaking, UK, government, signs, Paris, Agreement, world, is, first, comprehensive, treaty, on, tackling, climate, change, Ã, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12676</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @CLIMATECHANGE8: Alexandra Cousteau on climate change, the oceans and not eating tuna - Dallas News</td>\n",
       "      <td>26801</td>\n",
       "      <td>RT @CLIMATECHANGE8: Alexandra Cousteau on climate change, the oceans and not eating tuna - Dallas News</td>\n",
       "      <td>RT CLIMATECHANGE8 Alexandra Cousteau on climate change the oceans and not eating tuna  Dallas News</td>\n",
       "      <td>[RT, CLIMATECHANGE, 8, Alexandra, Cousteau, on, climate, change, the, oceans, and, not, eating, tuna, Dallas, News]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15816 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "11729          1   \n",
       "8308           1   \n",
       "7159           1   \n",
       "5644           1   \n",
       "6732           1   \n",
       "...          ...   \n",
       "12292          2   \n",
       "15209          2   \n",
       "7757           2   \n",
       "5707           2   \n",
       "12676          2   \n",
       "\n",
       "                                                                                                                                                  message  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "...                                                                                                                                                   ...   \n",
       "12292                                                                 Video: Statoil produces climate change 'roadmap' - News for the Oil and Gas Sector    \n",
       "15209                                                                RT @Reuters: In rare move, China criticizes Trump plan to exit climate change pact     \n",
       "7757                                RT @DonaldMacDona18: Global climate change battles being won in court  @IIGCCNews #climatechange #carbonbubble #COP2…   \n",
       "5707                          RT @BBCBreaking: UK government signs Paris Agreement, world's first comprehensive treaty on tackling climate change Ã¢â‚¬Â¦   \n",
       "12676                                             RT @CLIMATECHANGE8: Alexandra Cousteau on climate change, the oceans and not eating tuna - Dallas News    \n",
       "\n",
       "       tweetid  \\\n",
       "11729   977844   \n",
       "8308    441956   \n",
       "7159    978938   \n",
       "5644    587737   \n",
       "6732    804767   \n",
       "...        ...   \n",
       "12292   633554   \n",
       "15209   724243   \n",
       "7757    878987   \n",
       "5707    151024   \n",
       "12676    26801   \n",
       "\n",
       "                                                                                                                                   message_encoded_emojis  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "...                                                                                                                                                   ...   \n",
       "12292                                                                 Video: Statoil produces climate change 'roadmap' - News for the Oil and Gas Sector    \n",
       "15209                                                                RT @Reuters: In rare move, China criticizes Trump plan to exit climate change pact     \n",
       "7757                                RT @DonaldMacDona18: Global climate change battles being won in court  @IIGCCNews #climatechange #carbonbubble #COP2…   \n",
       "5707                          RT @BBCBreaking: UK government signs Paris Agreement, world's first comprehensive treaty on tackling climate change Ã¢â‚¬Â¦   \n",
       "12676                                             RT @CLIMATECHANGE8: Alexandra Cousteau on climate change, the oceans and not eating tuna - Dallas News    \n",
       "\n",
       "                                                                                                                                         message_clean  \\\n",
       "11729                    RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…   \n",
       "8308                                      YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA   \n",
       "7159                                          RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research    \n",
       "5644                                                       RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange   \n",
       "6732   RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "...                                                                                                                                                ...   \n",
       "12292                                                                  Video Statoil produces climate change roadmap  News for the Oil and Gas Sector    \n",
       "15209                                                                RT Reuters In rare move China criticizes Trump plan to exit climate change pact     \n",
       "7757                                   RT DonaldMacDona18 Global climate change battles being won in court  IIGCCNews climatechange carbonbubble COP2…   \n",
       "5707                         RT BBCBreaking UK government signs Paris Agreement world is first comprehensive treaty on tackling climate change Ã¢â‚¬Â¦   \n",
       "12676                                              RT CLIMATECHANGE8 Alexandra Cousteau on climate change the oceans and not eating tuna  Dallas News    \n",
       "\n",
       "                                                                                                                                                                                     tokens  \n",
       "11729                                  [RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]  \n",
       "8308                                                      [YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]  \n",
       "7159                                                             [RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]  \n",
       "5644                                                                               [RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]  \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]  \n",
       "...                                                                                                                                                                                     ...  \n",
       "12292                                                                                           [Video, Statoil, produces, climate, change, roadmap, News, for, the, Oil, and, Gas, Sector]  \n",
       "15209                                                                                        [RT, Reuters, In, rare, move, China, criticizes, Trump, plan, to, exit, climate, change, pact]  \n",
       "7757                                                    [RT, DonaldMacDona, 18, Global, climate, change, battles, being, won, in, court, IIGCCNews, climatechange, carbonbubble, COP, 2, …]  \n",
       "5707                                [RT, BBCBreaking, UK, government, signs, Paris, Agreement, world, is, first, comprehensive, treaty, on, tackling, climate, change, Ã, ¢, â, ‚, ¬, Â, ¦]  \n",
       "12676                                                                   [RT, CLIMATECHANGE, 8, Alexandra, Cousteau, on, climate, change, the, oceans, and, not, eating, tuna, Dallas, News]  \n",
       "\n",
       "[15816 rows x 6 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "def tokenize(df):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    df['tokens'] = df['message_clean'].apply(tokenizer.tokenize)\n",
    "    return df\n",
    "\n",
    "tokenize(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b8dbe356-b0a5-4a8b-b88e-98414bafcada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…</td>\n",
       "      <td>[RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, trees, …]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, wants, names, anyone, working, climate, change, research]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panels, end, first, term, Trump, thinks, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "11729          1   \n",
       "8308           1   \n",
       "7159           1   \n",
       "5644           1   \n",
       "6732           1   \n",
       "\n",
       "                                                                                                                                                  message  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "       tweetid  \\\n",
       "11729   977844   \n",
       "8308    441956   \n",
       "7159    978938   \n",
       "5644    587737   \n",
       "6732    804767   \n",
       "\n",
       "                                                                                                                                   message_encoded_emojis  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "                                                                                                                                         message_clean  \\\n",
       "11729                    RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…   \n",
       "8308                                      YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA   \n",
       "7159                                          RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research    \n",
       "5644                                                       RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange   \n",
       "6732   RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "                                                                                                                                                                                     tokens  \\\n",
       "11729                                  [RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]   \n",
       "8308                                                      [YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]   \n",
       "7159                                                             [RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]   \n",
       "5644                                                                               [RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]   \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]   \n",
       "\n",
       "                                                                                                                                       tokens_without_stopwords  \n",
       "11729                                             [RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, trees, …]  \n",
       "8308                                                          [YadiMoIina, gag, orders, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]  \n",
       "7159                                                       [RT, pattonoswalt, Not, ominous, He, also, wants, names, anyone, working, climate, change, research]  \n",
       "5644                                                                     [RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]  \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panels, end, first, term, Trump, thinks, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "def remove_stop_words(df):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Remove stopwords using a vectorized operation\n",
    "    df['tokens_without_stopwords'] = df['tokens'].apply(lambda tokens: [t for t in tokens if t not in stop_words])\n",
    "    return df\n",
    "\n",
    "remove_stop_words(df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "18b54f55-5c16-4987-b356-db7e6fdd6764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_without_stopwords</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…</td>\n",
       "      <td>[RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, trees, …]</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, tree, …]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]</td>\n",
       "      <td>[YadiMoIina, gag, order, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, wants, names, anyone, working, climate, change, research]</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, want, name, anyone, working, climate, change, research]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panels, end, first, term, Trump, thinks, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panel, end, first, term, Trump, think, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "11729          1   \n",
       "8308           1   \n",
       "7159           1   \n",
       "5644           1   \n",
       "6732           1   \n",
       "\n",
       "                                                                                                                                                  message  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "       tweetid  \\\n",
       "11729   977844   \n",
       "8308    441956   \n",
       "7159    978938   \n",
       "5644    587737   \n",
       "6732    804767   \n",
       "\n",
       "                                                                                                                                   message_encoded_emojis  \\\n",
       "11729                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "8308                                       @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "7159                                        RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "5644                                                    RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "                                                                                                                                         message_clean  \\\n",
       "11729                    RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…   \n",
       "8308                                      YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA   \n",
       "7159                                          RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research    \n",
       "5644                                                       RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange   \n",
       "6732   RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "                                                                                                                                                                                     tokens  \\\n",
       "11729                                  [RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]   \n",
       "8308                                                      [YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]   \n",
       "7159                                                             [RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]   \n",
       "5644                                                                               [RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]   \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]   \n",
       "\n",
       "                                                                                                                                       tokens_without_stopwords  \\\n",
       "11729                                             [RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, trees, …]   \n",
       "8308                                                          [YadiMoIina, gag, orders, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]   \n",
       "7159                                                       [RT, pattonoswalt, Not, ominous, He, also, wants, names, anyone, working, climate, change, research]   \n",
       "5644                                                                     [RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]   \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panels, end, first, term, Trump, thinks, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]   \n",
       "\n",
       "                                                                                                                                                        lemma  \n",
       "11729                                            [RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, tree, …]  \n",
       "8308                                                         [YadiMoIina, gag, order, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]  \n",
       "7159                                                       [RT, pattonoswalt, Not, ominous, He, also, want, name, anyone, working, climate, change, research]  \n",
       "5644                                                                   [RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]  \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panel, end, first, term, Trump, think, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "def lemmatize(words, lemmatizer):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_train['lemma'] = df_train['tokens_without_stopwords'].apply(lemmatize, args=(lemmatizer, ))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b0375-22d2-417c-9696-1c1779ef096c",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "### 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5094bf5f-a9f5-4f00-8f0d-cf1dfffa0f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000111</th>\n",
       "      <th>004</th>\n",
       "      <th>00kevin7</th>\n",
       "      <th>01</th>\n",
       "      <th>010536</th>\n",
       "      <th>012015</th>\n",
       "      <th>02</th>\n",
       "      <th>020</th>\n",
       "      <th>04</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_without_stopwords</th>\n",
       "      <th>lemma</th>\n",
       "      <th>differences</th>\n",
       "      <th>flattened_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…</td>\n",
       "      <td>[RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, trees, …]</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, tree, …]</td>\n",
       "      <td>[tree]</td>\n",
       "      <td>RT ubcforestry Funding GenomeBC support SallyNAitken team address impact climate change tree …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]</td>\n",
       "      <td>[YadiMoIina, gag, order, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]</td>\n",
       "      <td>[order]</td>\n",
       "      <td>YadiMoIina gag order Sure He definitely green think climate change hoax made CHINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, wants, names, anyone, working, climate, change, research]</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, want, name, anyone, working, climate, change, research]</td>\n",
       "      <td>[want, name]</td>\n",
       "      <td>RT pattonoswalt Not ominous He also want name anyone working climate change research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT MelissaJPeltier In case forgot Chinese Hoax global warming climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panels, end, first, term, Trump, thinks, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panel, end, first, term, Trump, think, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]</td>\n",
       "      <td>[panel, think]</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half billion solar panel end first term Trump think climate change hoaxÃ ¢ â ‚ ¬ Â ¦</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000111  004  00kevin7  01  010536  012015  02  020  04  07  ...  sentiment  \\\n",
       "0       0    0         0   0       0       0   0    0   0   0  ...          1   \n",
       "1       0    0         0   0       0       0   0    0   0   0  ...          1   \n",
       "2       0    0         0   0       0       0   0    0   0   0  ...          1   \n",
       "3       0    0         0   0       0       0   0    0   0   0  ...          1   \n",
       "4       0    0         0   0       0       0   0    0   0   0  ...          1   \n",
       "\n",
       "                                                                                                                                              message  \\\n",
       "0                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "1                                      @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "2                                       RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "3                                                   RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "4  RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "   tweetid  \\\n",
       "0   977844   \n",
       "1   441956   \n",
       "2   978938   \n",
       "3   587737   \n",
       "4   804767   \n",
       "\n",
       "                                                                                                                               message_encoded_emojis  \\\n",
       "0                   RT @ubcforestry: Funding from @GenomeBC will support @SallyNAitken's team as they address the impact of climate change on trees.…   \n",
       "1                                      @YadiMoIina gag orders? Sure. He's definitely green and doesn't think climate change was a hoax made by CHINA.   \n",
       "2                                       RT @pattonoswalt: Not ominous at all! (He also wants the names of anyone working on climate change research)    \n",
       "3                                                   RT @MelissaJPeltier: In case you forgot about that 'Chinese Hoax' global warming:  #climatechange   \n",
       "4  RT @SethMacFarlane: HRC proposes installing half a billion solar panels by the end of her first term. Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "                                                                                                                                     message_clean  \\\n",
       "0                    RT ubcforestry Funding from GenomeBC will support SallyNAitken is team as they address the impact of climate change on trees…   \n",
       "1                                     YadiMoIina gag orders Sure He is definitely green and does not think climate change was a hoax made by CHINA   \n",
       "2                                         RT pattonoswalt Not ominous at all He also wants the names of anyone working on climate change research    \n",
       "3                                                      RT MelissaJPeltier In case you forgot about that Chinese Hoax global warming  climatechange   \n",
       "4  RT SethMacFarlane HRC proposes installing half a billion solar panels by the end of her first term Trump thinks climate change is a hoaxÃ¢â‚¬Â¦   \n",
       "\n",
       "                                                                                                                                                                                 tokens  \\\n",
       "0                                  [RT, ubcforestry, Funding, from, GenomeBC, will, support, SallyNAitken, is, team, as, they, address, the, impact, of, climate, change, on, trees, …]   \n",
       "1                                                     [YadiMoIina, gag, orders, Sure, He, is, definitely, green, and, does, not, think, climate, change, was, a, hoax, made, by, CHINA]   \n",
       "2                                                            [RT, pattonoswalt, Not, ominous, at, all, He, also, wants, the, names, of, anyone, working, on, climate, change, research]   \n",
       "3                                                                              [RT, MelissaJPeltier, In, case, you, forgot, about, that, Chinese, Hoax, global, warming, climatechange]   \n",
       "4  [RT, SethMacFarlane, HRC, proposes, installing, half, a, billion, solar, panels, by, the, end, of, her, first, term, Trump, thinks, climate, change, is, a, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]   \n",
       "\n",
       "                                                                                                                                   tokens_without_stopwords  \\\n",
       "0                                             [RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, trees, …]   \n",
       "1                                                         [YadiMoIina, gag, orders, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]   \n",
       "2                                                      [RT, pattonoswalt, Not, ominous, He, also, wants, names, anyone, working, climate, change, research]   \n",
       "3                                                                    [RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]   \n",
       "4  [RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panels, end, first, term, Trump, thinks, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]   \n",
       "\n",
       "                                                                                                                                                    lemma  \\\n",
       "0                                            [RT, ubcforestry, Funding, GenomeBC, support, SallyNAitken, team, address, impact, climate, change, tree, …]   \n",
       "1                                                        [YadiMoIina, gag, order, Sure, He, definitely, green, think, climate, change, hoax, made, CHINA]   \n",
       "2                                                      [RT, pattonoswalt, Not, ominous, He, also, want, name, anyone, working, climate, change, research]   \n",
       "3                                                                  [RT, MelissaJPeltier, In, case, forgot, Chinese, Hoax, global, warming, climatechange]   \n",
       "4  [RT, SethMacFarlane, HRC, proposes, installing, half, billion, solar, panel, end, first, term, Trump, think, climate, change, hoaxÃ, ¢, â, ‚, ¬, Â, ¦]   \n",
       "\n",
       "      differences  \\\n",
       "0          [tree]   \n",
       "1         [order]   \n",
       "2    [want, name]   \n",
       "3              []   \n",
       "4  [panel, think]   \n",
       "\n",
       "                                                                                                                  flattened_lemma  \n",
       "0                                  RT ubcforestry Funding GenomeBC support SallyNAitken team address impact climate change tree …  \n",
       "1                                              YadiMoIina gag order Sure He definitely green think climate change hoax made CHINA  \n",
       "2                                            RT pattonoswalt Not ominous He also want name anyone working climate change research  \n",
       "3                                                     RT MelissaJPeltier In case forgot Chinese Hoax global warming climatechange  \n",
       "4  RT SethMacFarlane HRC proposes installing half billion solar panel end first term Trump think climate change hoaxÃ ¢ â ‚ ¬ Â ¦  \n",
       "\n",
       "[5 rows x 10683 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert into Bag Of Words using CountVectorizer\n",
    "def vectorize(df, max_df, min_df, ngram_range, max_features):\n",
    "    # Flatten the list of lists into a single list of strings\n",
    "    df['flattened_lemma'] = df['lemma'].apply(lambda word_list: ' '.join(word_list))\n",
    "    # Create and fit the CountVectorizer\n",
    "    vect = CountVectorizer(lowercase=True, max_df=max_df, min_df=min_df, ngram_range=ngram_range,\n",
    "                           max_features=max_features)\n",
    "    vect.fit(df_train['flattened_lemma'])  # Note that the vectorizer is always fit on the train data, so that both\n",
    "                                           # train and test sets are vectorized on the same vocabulary\n",
    "    X = vect.transform(df['flattened_lemma'])\n",
    "    bag_of_words = pd.DataFrame(X.toarray(), columns=vect.get_feature_names_out())\n",
    "    # Merge original dataset with Bag Of Words\n",
    "    bag_of_words.reset_index(drop=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    vectorized_df = pd.concat([bag_of_words, df],axis=1)\n",
    "    return vectorized_df\n",
    "    \n",
    "df_train = vectorize(df_train, MAX_DF, MIN_DF, NGRAM_RANGE, MAX_FEATURES)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78f7b064-43e5-4f67-bead-75220c0a42db",
   "metadata": {},
   "source": [
    "# Convert into Bag Of Words using TF-IDF vectorizer\n",
    "def vectorize(df, max_df, min_df, ngram_range, max_features):\n",
    "    # Flatten the list of lists into a single list of strings\n",
    "    df['flattened_lemma'] = df['lemma'].apply(lambda word_list: ' '.join(word_list))\n",
    "    # Create and fit the CountVectorizer\n",
    "    vect = TfidfVectorizer(max_features=max_features, lowercase=True,max_df=max_df,min_df=min_df,ngram_range=ngram_range)\n",
    "    vect.fit(df_train['flattened_lemma'])  # Note that the vectorizer is always fit on the train data, so that both\n",
    "                                           # train and test sets are vectorized on the same vocabulary\n",
    "    X = vect.transform(df['flattened_lemma'])\n",
    "    bag_of_words = pd.DataFrame(X.toarray(), columns=vect.get_feature_names_out())\n",
    "    # Merge original dataset with Bag Of Words\n",
    "    bag_of_words.reset_index(drop=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    vectorized_df = pd.concat([bag_of_words, df],axis=1)\n",
    "    return vectorized_df\n",
    "    \n",
    "df_train = vectorize(df_train, MAX_DF, MIN_DF, NGRAM_RANGE, MAX_FEATURES)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6b34223-0ec9-4cc2-9db0-30d3a03e2e8d",
   "metadata": {},
   "source": [
    "grouped = df_train.groupby('sentiment').sum()\n",
    "top_n = 10\n",
    "top_words_per_class = {}\n",
    "for class_name, row in grouped.iterrows():\n",
    "    top_words = row.sort_values(ascending=False)[:top_n]\n",
    "    top_words_per_class[class_name] = top_words\n",
    "\n",
    "# Create bar plots for top 10 words per class\n",
    "for class_name, top_words in top_words_per_class.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_words.plot(kind='bar', color='skyblue')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Top {top_n} Words in {class_name}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ff841-4930-4c6d-bd95-b1d363eba581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f347f-2108-4c7e-a05f-56d7aeb03310",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "### 6. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "1eb29688-0b6a-40c7-a11f-174eb1de1209",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 322. MiB for an array with shape (3954, 10672) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[296], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_train_kbest, y\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train, X_test, y_train, y_test\n\u001b[1;32m---> 17\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m split_train_test(df_train)\n",
      "Cell \u001b[1;32mIn[296], line 13\u001b[0m, in \u001b[0;36msplit_train_test\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     11\u001b[0m selector_kbest \u001b[38;5;241m=\u001b[39m feature_selection\u001b[38;5;241m.\u001b[39mSelectKBest(score_func\u001b[38;5;241m=\u001b[39mf_classif, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Transform (i.e.: run selection on) the training data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train_kbest \u001b[38;5;241m=\u001b[39m selector_kbest\u001b[38;5;241m.\u001b[39mfit_transform(X, y)\n\u001b[0;32m     14\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_train_kbest, y\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_train, X_test, y_train, y_test\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:503\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    498\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    499\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m], multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    500\u001b[0m )\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[1;32m--> 503\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(score_func_ret, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpvalues_ \u001b[38;5;241m=\u001b[39m score_func_ret\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:155\u001b[0m, in \u001b[0;36mf_classif\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    153\u001b[0m X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    154\u001b[0m args \u001b[38;5;241m=\u001b[39m [X[safe_mask(X, y \u001b[38;5;241m==\u001b[39m k)] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y)]\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f_oneway(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:93\u001b[0m, in \u001b[0;36mf_oneway\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform a 1-way ANOVA.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mThe one-way ANOVA tests the null hypothesis that 2 or more groups have\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m.. [2] Heiman, G.W.  Research Methods in Statistics. 2002.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args)\n\u001b[1;32m---> 93\u001b[0m args \u001b[38;5;241m=\u001b[39m [as_float_array(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m     94\u001b[0m n_samples_per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[0;32m     95\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(n_samples_per_class)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:93\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform a 1-way ANOVA.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mThe one-way ANOVA tests the null hypothesis that 2 or more groups have\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m.. [2] Heiman, G.W.  Research Methods in Statistics. 2002.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args)\n\u001b[1;32m---> 93\u001b[0m args \u001b[38;5;241m=\u001b[39m [as_float_array(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m     94\u001b[0m n_samples_per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[0;32m     95\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(n_samples_per_class)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:266\u001b[0m, in \u001b[0;36mas_float_array\u001b[1;34m(X, copy, force_all_finite)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m     return_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;241m.\u001b[39mastype(return_dtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 322. MiB for an array with shape (3954, 10672) and data type float64"
     ]
    }
   ],
   "source": [
    "# Split into training and test data\n",
    "def split_train_test(df):\n",
    "    X = df.copy()\n",
    "    y = X.sentiment\n",
    "    columns_to_drop = X.select_dtypes(include=['object']).columns\n",
    "    columns_to_drop = list(columns_to_drop) + ['tweetid', 'sentiment']\n",
    "    X.drop(columns=columns_to_drop,inplace=True)\n",
    "    # Reduce features\n",
    "    kbest = LogisticRegression()\n",
    "    # Set up selector, choosing score function and number of features to retain\n",
    "    selector_kbest = feature_selection.SelectKBest(score_func=f_classif, k=200)\n",
    "    # Transform (i.e.: run selection on) the training data\n",
    "    X_train_kbest = selector_kbest.fit_transform(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_kbest, y.values)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_train_test(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b615264-745c-4d5e-aeb1-5566eb6df8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the classifiers\n",
    "names = [\n",
    "         'Logistic Regression', \n",
    "         'Nearest Neighbors',\n",
    "         #'Linear SVM',\n",
    "         'RBF SVM',\n",
    "         'Decision Tree',\n",
    "         'Random Forest',\n",
    "         'AdaBoost'\n",
    "         ]\n",
    "\n",
    "classifiers = [\n",
    "               LogisticRegression(max_iter=1000),\n",
    "               KNeighborsClassifier(3),\n",
    "               #SVC(kernel=\"linear\", C=0.025),\n",
    "               SVC(gamma=1, C=1),\n",
    "               DecisionTreeClassifier(max_depth=5),\n",
    "               RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "               AdaBoostClassifier()\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56e167-6788-4219-a6e4-e75a5054cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "\n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf\n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)\n",
    "\n",
    "print ('... All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad4ef0-96f4-4df5-962b-37e75a29ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('F1 Train', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c6f3f-24cf-47e4-a394-5277e5bbfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "results.sort_values('F1 Train', ascending=False, inplace=True)\n",
    "results.plot(y=['F1 Test'], kind='bar', ax=ax[0], xlim=[0,1.1], ylim=[0.05,0.99])\n",
    "results.plot(y='Train Time', kind='bar', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b66a1c-fbd6-42cd-b6aa-71dc8abe7bfd",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "### 7. Model performance evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e3110ea-d6a7-4cce-bb7d-8fed60ffc817",
   "metadata": {},
   "source": [
    "# Use K-Fold cross validation\n",
    "cv = []\n",
    "for name, model in models.items():\n",
    "    print ()\n",
    "    print(name)\n",
    "    scores = cross_val_score(model, X=X_train, y=y_train, cv=5)\n",
    "    print(\"Accuracy: {:0.2f} (+/- {:0.4f})\".format(scores.mean(), scores.std()))\n",
    "    cv.append([name, scores.mean(), scores.std() ])\n",
    "\n",
    "cv = pd.DataFrame(cv, columns=['Model', 'CV_Mean', 'CV_Std_Dev'])\n",
    "cv.set_index('Model', inplace=True)\n",
    "\n",
    "cv.plot(y='CV_Mean', yerr='CV_Std_Dev',kind='bar', ylim=[0.15, 0.95])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e16edec0-e9fd-4285-8f99-f008bfa38791",
   "metadata": {},
   "source": [
    "# GridSearchCV\n",
    "# Do for KNN\n",
    "\n",
    "ks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in ks:\n",
    "    print('Fitting KNN model with k = {:d}'.format(k))\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    run_time = %timeit -q -o knn.fit(X_train, y_train)\n",
    "\n",
    "    # predicting\n",
    "    y_pred = knn.predict(X_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "\n",
    "    # scoring\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "    # save the results \n",
    "    results.append([k, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "results = pd.DataFrame(results, columns=['KNN', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('KNN', inplace= True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8060330-bd6a-4e1c-b2d5-1c18930dcfae",
   "metadata": {},
   "source": [
    "<a id=\"eight\"></a>\n",
    "### 8. Model analysis and conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7774055e-780a-45c9-a038-9d519b4cf049",
   "metadata": {},
   "source": [
    "# GridSearchCV for SVM (RBF)\n",
    "param_grid = {'kernel': ['rbf'],\n",
    "              'gamma': (0.5,1,2),\n",
    "              'C': (0.5,0.75,1.0)}\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, param_grid, scoring='f1_macro', cv=2)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d182252c-6761-4314-90f0-5c24382d55a6",
   "metadata": {},
   "source": [
    "svm = SVC(kernel='rbf', gamma=1.0, C=1.0)\n",
    "clf = svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "print ('... scoring')\n",
    "accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "\n",
    "f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print(f'f1-test: {f1_test}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a676ad-8a98-4887-99fd-c452a912e400",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# See how it performs with 500 features\n",
    "\n",
    "df_train2 = pd.read_csv('G:/My Drive/Professionele ontwikkeling/Data Science/Explore Data Science Course/Sprint 6_Advanced Classification/Predict/advanced-classification-predict/data/train.csv')\n",
    "remove_noise(df_train2)\n",
    "process_emoticons(df_train2)\n",
    "df_train2['message_clean'] = df_train2['message_encoded_emojis'].apply(remove_punctuation)\n",
    "tokenize(df_train2)\n",
    "df_train2['tokens_without_stopwords'] = df_train2['tokens'].apply(remove_stop_words)\n",
    "df_train2['lemma'] = df_train2['tokens_without_stopwords'].apply(lemmatize, args=(lemmatizer, ))\n",
    "df_train2 = vectorize(df_train2, MAX_DF, MIN_DF, NGRAM_RANGE, 500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_train_test(df_train2)\n",
    "\n",
    "\n",
    "names = [\n",
    "         #'Logistic Regression', \n",
    "         #'Nearest Neighbors'#,\n",
    "         #'Linear SVM',\n",
    "         'RBF SVM'#,\n",
    "         #'Decision Tree',\n",
    "         #'Random Forest',\n",
    "         #'AdaBoost'\n",
    "         ]\n",
    "\n",
    "classifiers = [\n",
    "               #LogisticRegression(max_iter=1000),\n",
    "               #KNeighborsClassifier(1)#,\n",
    "               #SVC(kernel=\"linear\", C=0.025),\n",
    "               SVC(gamma=1, C=1)#,\n",
    "               #DecisionTreeClassifier(max_depth=5),\n",
    "               #RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "               #AdaBoostClassifier()\n",
    "               ]\n",
    "\n",
    "# Train all the models\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "\n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf\n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)\n",
    "\n",
    "print ('... All done!')\n",
    "print(results.sort_values('F1 Train', ascending=False))\n",
    "\n",
    "# Use K-Fold cross validation\n",
    "\n",
    "\"\"\"\n",
    "cv = []\n",
    "for name, model in models.items():\n",
    "    print ()\n",
    "    print(name)\n",
    "    scores = cross_val_score(model, X=X.values, y=y.values, cv=10)\n",
    "    print(\"Accuracy: {:0.2f} (+/- {:0.4f})\".format(scores.mean(), scores.std()))\n",
    "    cv.append([name, scores.mean(), scores.std() ])\n",
    "\n",
    "cv = pd.DataFrame(cv, columns=['Model', 'CV_Mean', 'CV_Std_Dev'])\n",
    "cv.set_index('Model', inplace=True)\n",
    "\n",
    "cv.plot(y='CV_Mean', yerr='CV_Std_Dev',kind='bar', ylim=[0.25, 0.99])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd06b96-392c-483e-82e2-ceee9107be65",
   "metadata": {},
   "source": [
    "## Process test data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64c2e034-a8b7-4680-8d20-20385b4e40c1",
   "metadata": {},
   "source": [
    "df_test = pd.read_csv('G:/My Drive/Professionele ontwikkeling/Data Science/Explore Data Science Course/Sprint 6_Advanced Classification/Predict/advanced-classification-predict/data/test_with_no_labels.csv')\n",
    "remove_noise(df_test)\n",
    "process_emoticons(df_test)\n",
    "df_test['message_clean'] = df_test['message_encoded_emojis'].apply(remove_punctuation)\n",
    "tokenize(df_test)\n",
    "remove_stop_words(df_test)\n",
    "df_test['lemma'] = df_test['tokens_without_stopwords'].apply(lemmatize, args=(lemmatizer, ))\n",
    "df_test = vectorize(df_test, MAX_DF, MIN_DF, NGRAM_RANGE, MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e42436a2-6a69-4a44-bff5-8b5a34f2003c",
   "metadata": {},
   "source": [
    "# Make predictions on test data\n",
    "columns_to_drop = df_test.select_dtypes(include=['object']).columns\n",
    "columns_to_drop = list(columns_to_drop) + ['tweetid']\n",
    "X = df_test.copy()\n",
    "X.drop(columns=columns_to_drop,inplace=True)\n",
    "trained_model = models['Nearest Neighbors']\n",
    "y_pred = trained_model.predict(X.values)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b09c415f-1873-46c3-8d05-f7aeb1b49143",
   "metadata": {},
   "source": [
    "# Create the prediction upload file\n",
    "\n",
    "submission_df = pd.DataFrame()\n",
    "submission_df['tweetid'] = df_test.tweetid\n",
    "submission_df['sentiment'] = y_pred\n",
    "submission_df.to_csv('dawieloots_predict_v3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
