{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0034c475-0962-4dcc-934f-049f92c09cb3",
   "metadata": {},
   "source": [
    "# ADVANCED CLASSIFICATION PREDICT\n",
    "#### By Dawie Loots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12042635-3289-40ca-82f7-56c93dac89b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Honour Code\n",
    "\n",
    "I, Dawie Loots, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20841b8a-2fde-431a-9590-7047a4b486fc",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Predict overview</a>\n",
    "\n",
    "<a href=#two>2. Importing packages</a>\n",
    "\n",
    "<a href=#three>3. Loading the data</a>\n",
    "\n",
    "<a href=#four>4. Data Preprocessing</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis</a>\n",
    "\n",
    "<a href=#six>6. Modeling</a>\n",
    "\n",
    "<a href=#seven>7. Model performance evaluation</a>\n",
    "\n",
    "<a href=#eight>8. Model analysis and conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e51577-c2e5-46cd-84bf-c442505f77a5",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "### 1. Predict overview\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "With this context, EA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabfd0c-c251-4974-8b2a-3d768ce46ed5",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "### 2. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bad7e9a6-467d-45f7-9231-da6134ab143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import chardet # To provide a best estimate of the encoding that was used in the text data\n",
    "import io # For string operations\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import re\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "PARAMETER_CONSTANT = 42  # This is the seed value for random number generation\n",
    "# Vectorizer constants\n",
    "MAX_DF = 0.5\n",
    "MIN_DF = 2\n",
    "NGRAM_RANGE = (1,2)\n",
    "MAX_FEATURES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3762b8e-2add-425f-8678-9dcb6f373fcc",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "### 3. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76838241-36bb-4953-bbb9-0d0dbd5e44e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('G:/My Drive/Professionele ontwikkeling/Data Science/Explore Data Science Course/Sprint 6_Advanced Classification/Predict/advanced-classification-predict/data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5c80fe6-a9f0-4c8b-a5bd-63f35f2aa847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6131b-fd90-4cce-8b01-acb12fb175af",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "### 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e004d5b-c9f3-4581-a49d-027009259959",
   "metadata": {},
   "source": [
    "Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a70b03ae-824c-42f0-907a-d9e8327dc16b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2126f41-6fc6-4aee-a1ee-12e6e7b54d86",
   "metadata": {},
   "source": [
    "There is no missing data, so let's proceed by checking for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5efdf0e3-5f0f-4394-9828-521f736c0e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count = df_train['sentiment'].value_counts()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1b6f-ec7c-470a-9d79-ff95cdcf3df1",
   "metadata": {},
   "source": [
    "Seems like most of the tweets were for class 1 (supporting the belief of man-made changes)\n",
    "Let's divide the total 15,819 tweets by 4, to get +- 3,955 per class.  We will need to upsamle classes 0, -1 and 2, and downsample class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f16beeed-2167-42ce-92c2-be317a239918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3954\n",
       "-1    3954\n",
       " 0    3954\n",
       " 2    3954\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_min1 = df_train[df_train['sentiment']==-1]\n",
    "class_0 = df_train[df_train['sentiment']==0]\n",
    "class_1 = df_train[df_train['sentiment']==1]\n",
    "class_2 = df_train[df_train['sentiment']==2]\n",
    "balance = len(df_train) // 4 # The number of samples that will result in class balance\n",
    "df_train_class1_resampled = resample(class_1,\n",
    "                            replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "df_train_classmin1_resampled = resample(class_min1,\n",
    "                            replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "df_train_class0_resampled = resample(class_0,\n",
    "                            replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "df_train_class2_resampled = resample(class_2,\n",
    "                            replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                            n_samples=balance, # make all classes equal\n",
    "                            random_state=27) # reproducible results\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True) # Reset index before upsampling\n",
    "df_train = pd.concat([df_train_class1_resampled, df_train_classmin1_resampled, \n",
    "                                df_train_class0_resampled, df_train_class2_resampled])\n",
    "df_train.set_index(df_train.index, inplace=True) # Set the default integer index as the new index after upsampling\n",
    "\n",
    "# Check new class counts\n",
    "df_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b6a1c-d625-4153-87b0-cb821c6d09c7",
   "metadata": {},
   "source": [
    "Now that we have class balance, let's proceed with the following steps to convert text into numerical values, so that it can be used for this classification task:\n",
    "\n",
    "- Removing noise (such as web-urls)\n",
    "- Removing punctuation\n",
    "- Tokenization\n",
    "- Removal of stop words\n",
    "- Lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ad8fee8-859c-4382-9c96-21a61c44d114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>977844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>441956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>978938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>587737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>804767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid\n",
       "11729          1  RT @ubcforestry: Funding from @GenomeBC will s...   977844\n",
       "8308           1  @YadiMoIina gag orders? Sure. He's definitely ...   441956\n",
       "7159           1  RT @pattonoswalt: Not ominous at all! (He also...   978938\n",
       "5644           1  RT @MelissaJPeltier: In case you forgot about ...   587737\n",
       "6732           1  RT @SethMacFarlane: HRC proposes installing ha...   804767"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove noise (all hyperlinks)\n",
    "\n",
    "def remove_noise(df):\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'   # Find all hyperlinks\n",
    "    subs_url = r''\n",
    "    df['message'] = df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "    return df\n",
    "\n",
    "remove_noise(df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd6cfba5-dfe3-4d55-8051-70dab081df9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Greenpeace: Sad :( Animals and birds which...</td>\n",
       "      <td>909808</td>\n",
       "      <td>RT @Greenpeace: Sad frowning_face_emoticon Ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>1</td>\n",
       "      <td>@timesofindia why do fishermen always fish muc...</td>\n",
       "      <td>855852</td>\n",
       "      <td>@timesofindia why do fishermen always fish muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @savitriyaca: a must watch, cause climate c...</td>\n",
       "      <td>891447</td>\n",
       "      <td>RT @savitriyaca: a must watch, cause climate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11203</th>\n",
       "      <td>1</td>\n",
       "      <td>@trees_r_cool animal agriculture is the main c...</td>\n",
       "      <td>164712</td>\n",
       "      <td>@trees_r_cool animal agriculture is the main c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15225</th>\n",
       "      <td>1</td>\n",
       "      <td>@KamalaHarris Start with a Pareto of biggest c...</td>\n",
       "      <td>307036</td>\n",
       "      <td>@KamalaHarris Start with a Pareto of biggest c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1</td>\n",
       "      <td>Whenever it randomly snows like this I get v w...</td>\n",
       "      <td>166148</td>\n",
       "      <td>Whenever it randomly snows like this I get v w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>0</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxi...</td>\n",
       "      <td>152968</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>0</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxi...</td>\n",
       "      <td>152968</td>\n",
       "      <td>EPA head Scott Pruitt denies that carbon dioxi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "2549           1  RT @Greenpeace: Sad :( Animals and birds which...   909808   \n",
       "4687           1  @timesofindia why do fishermen always fish muc...   855852   \n",
       "11386          1  RT @savitriyaca: a must watch, cause climate c...   891447   \n",
       "11203          1  @trees_r_cool animal agriculture is the main c...   164712   \n",
       "15225          1  @KamalaHarris Start with a Pareto of biggest c...   307036   \n",
       "1038           1  Whenever it randomly snows like this I get v w...   166148   \n",
       "5200           0  EPA head Scott Pruitt denies that carbon dioxi...   152968   \n",
       "5200           0  EPA head Scott Pruitt denies that carbon dioxi...   152968   \n",
       "\n",
       "                                  message_encoded_emojis  \n",
       "2549   RT @Greenpeace: Sad frowning_face_emoticon Ani...  \n",
       "4687   @timesofindia why do fishermen always fish muc...  \n",
       "11386  RT @savitriyaca: a must watch, cause climate c...  \n",
       "11203  @trees_r_cool animal agriculture is the main c...  \n",
       "15225  @KamalaHarris Start with a Pareto of biggest c...  \n",
       "1038   Whenever it randomly snows like this I get v w...  \n",
       "5200   EPA head Scott Pruitt denies that carbon dioxi...  \n",
       "5200   EPA head Scott Pruitt denies that carbon dioxi...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle emoticons\n",
    "def process_emoticons(df):\n",
    "    emoticon_dictionary = {':\\)': 'smiley_face_emoticon',\n",
    "                           ':\\(': 'frowning_face_emoticon',\n",
    "                           ':D': 'grinning_face_emoticon',\n",
    "                           ':P': 'sticking_out_tongue_emoticon',\n",
    "                           ';\\)': 'winking_face_emoticon',\n",
    "                           ':o': 'surprised_face_emoticon',\n",
    "                           ':\\|': 'neutral_face_emoticon',\n",
    "                           ':\\'\\)': 'tears_of_joy_emoticon',\n",
    "                           ':\\'\\(': 'crying_face_emoticon'}\n",
    "\n",
    "    df['message_encoded_emojis'] = df['message'].replace(emoticon_dictionary, regex=True)\n",
    "    return df\n",
    "\n",
    "process_emoticons(df_train)\n",
    "# Check if it was correctly \n",
    "emoji_rows = df_train[df_train['message'].str.contains(':\\(')]\n",
    "emoji_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9402beb4-2117-4d0d-b77c-4b6e2ab4cb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "11729          1  RT @ubcforestry: Funding from @GenomeBC will s...   977844   \n",
       "8308           1  @YadiMoIina gag orders? Sure. He's definitely ...   441956   \n",
       "7159           1  RT @pattonoswalt: Not ominous at all! (He also...   978938   \n",
       "5644           1  RT @MelissaJPeltier: In case you forgot about ...   587737   \n",
       "6732           1  RT @SethMacFarlane: HRC proposes installing ha...   804767   \n",
       "\n",
       "                                  message_encoded_emojis  \\\n",
       "11729  RT @ubcforestry: Funding from @GenomeBC will s...   \n",
       "8308   @YadiMoIina gag orders? Sure. He's definitely ...   \n",
       "7159   RT @pattonoswalt: Not ominous at all! (He also...   \n",
       "5644   RT @MelissaJPeltier: In case you forgot about ...   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing ha...   \n",
       "\n",
       "                                           message_clean  \n",
       "11729  RT ubcforestry Funding from GenomeBC will supp...  \n",
       "8308   YadiMoIina gag orders Sure He is definitely gr...  \n",
       "7159   RT pattonoswalt Not ominous at all He also wan...  \n",
       "5644   RT MelissaJPeltier In case you forgot about th...  \n",
       "6732   RT SethMacFarlane HRC proposes installing half...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation and expand all contracted words\n",
    "def remove_punctuation(message):\n",
    "    contractions = {\"'t\": \" not\",\"'s\": \" is\",\"'re\": \" are\",\"'ll\": \" will\", \"'m\": \" am\"}\n",
    "    pattern = re.compile(r\"\\b(\" + \"|\".join(re.escape(key) for key in contractions.keys()) + r\")\\b\")\n",
    "    message = re.sub(r\"n't\\b\", \" not\", message) # Replace \"n't\" with \" not\"\n",
    "    message = pattern.sub(lambda match: contractions[match.group(0)], message) # Replace all other contractions except for \"n't\"\n",
    "    return ''.join([l for l in message if l not in string.punctuation])\n",
    "\n",
    "df_train['message_clean'] = df_train['message_encoded_emojis'].apply(remove_punctuation)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23b14d0b-108c-4e62-b980-d6978c6b2e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will supp...</td>\n",
       "      <td>[RT, ubcforestry, Funding, from, GenomeBC, wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely gr...</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, is, defini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wan...</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, at, all, He, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about th...</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, you, forgot, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half...</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12292</th>\n",
       "      <td>2</td>\n",
       "      <td>Video: Statoil produces climate change 'roadma...</td>\n",
       "      <td>633554</td>\n",
       "      <td>Video: Statoil produces climate change 'roadma...</td>\n",
       "      <td>Video Statoil produces climate change roadmap ...</td>\n",
       "      <td>[Video, Statoil, produces, climate, change, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15209</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @Reuters: In rare move, China criticizes Tr...</td>\n",
       "      <td>724243</td>\n",
       "      <td>RT @Reuters: In rare move, China criticizes Tr...</td>\n",
       "      <td>RT Reuters In rare move China criticizes Trump...</td>\n",
       "      <td>[RT, Reuters, In, rare, move, China, criticize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @DonaldMacDona18: Global climate change bat...</td>\n",
       "      <td>878987</td>\n",
       "      <td>RT @DonaldMacDona18: Global climate change bat...</td>\n",
       "      <td>RT DonaldMacDona18 Global climate change battl...</td>\n",
       "      <td>[RT, DonaldMacDona, 18, Global, climate, chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @BBCBreaking: UK government signs Paris Agr...</td>\n",
       "      <td>151024</td>\n",
       "      <td>RT @BBCBreaking: UK government signs Paris Agr...</td>\n",
       "      <td>RT BBCBreaking UK government signs Paris Agree...</td>\n",
       "      <td>[RT, BBCBreaking, UK, government, signs, Paris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12676</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @CLIMATECHANGE8: Alexandra Cousteau on clim...</td>\n",
       "      <td>26801</td>\n",
       "      <td>RT @CLIMATECHANGE8: Alexandra Cousteau on clim...</td>\n",
       "      <td>RT CLIMATECHANGE8 Alexandra Cousteau on climat...</td>\n",
       "      <td>[RT, CLIMATECHANGE, 8, Alexandra, Cousteau, on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15816 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "11729          1  RT @ubcforestry: Funding from @GenomeBC will s...   977844   \n",
       "8308           1  @YadiMoIina gag orders? Sure. He's definitely ...   441956   \n",
       "7159           1  RT @pattonoswalt: Not ominous at all! (He also...   978938   \n",
       "5644           1  RT @MelissaJPeltier: In case you forgot about ...   587737   \n",
       "6732           1  RT @SethMacFarlane: HRC proposes installing ha...   804767   \n",
       "...          ...                                                ...      ...   \n",
       "12292          2  Video: Statoil produces climate change 'roadma...   633554   \n",
       "15209          2  RT @Reuters: In rare move, China criticizes Tr...   724243   \n",
       "7757           2  RT @DonaldMacDona18: Global climate change bat...   878987   \n",
       "5707           2  RT @BBCBreaking: UK government signs Paris Agr...   151024   \n",
       "12676          2  RT @CLIMATECHANGE8: Alexandra Cousteau on clim...    26801   \n",
       "\n",
       "                                  message_encoded_emojis  \\\n",
       "11729  RT @ubcforestry: Funding from @GenomeBC will s...   \n",
       "8308   @YadiMoIina gag orders? Sure. He's definitely ...   \n",
       "7159   RT @pattonoswalt: Not ominous at all! (He also...   \n",
       "5644   RT @MelissaJPeltier: In case you forgot about ...   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing ha...   \n",
       "...                                                  ...   \n",
       "12292  Video: Statoil produces climate change 'roadma...   \n",
       "15209  RT @Reuters: In rare move, China criticizes Tr...   \n",
       "7757   RT @DonaldMacDona18: Global climate change bat...   \n",
       "5707   RT @BBCBreaking: UK government signs Paris Agr...   \n",
       "12676  RT @CLIMATECHANGE8: Alexandra Cousteau on clim...   \n",
       "\n",
       "                                           message_clean  \\\n",
       "11729  RT ubcforestry Funding from GenomeBC will supp...   \n",
       "8308   YadiMoIina gag orders Sure He is definitely gr...   \n",
       "7159   RT pattonoswalt Not ominous at all He also wan...   \n",
       "5644   RT MelissaJPeltier In case you forgot about th...   \n",
       "6732   RT SethMacFarlane HRC proposes installing half...   \n",
       "...                                                  ...   \n",
       "12292  Video Statoil produces climate change roadmap ...   \n",
       "15209  RT Reuters In rare move China criticizes Trump...   \n",
       "7757   RT DonaldMacDona18 Global climate change battl...   \n",
       "5707   RT BBCBreaking UK government signs Paris Agree...   \n",
       "12676  RT CLIMATECHANGE8 Alexandra Cousteau on climat...   \n",
       "\n",
       "                                                  tokens  \n",
       "11729  [RT, ubcforestry, Funding, from, GenomeBC, wil...  \n",
       "8308   [YadiMoIina, gag, orders, Sure, He, is, defini...  \n",
       "7159   [RT, pattonoswalt, Not, ominous, at, all, He, ...  \n",
       "5644   [RT, MelissaJPeltier, In, case, you, forgot, a...  \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing...  \n",
       "...                                                  ...  \n",
       "12292  [Video, Statoil, produces, climate, change, ro...  \n",
       "15209  [RT, Reuters, In, rare, move, China, criticize...  \n",
       "7757   [RT, DonaldMacDona, 18, Global, climate, chang...  \n",
       "5707   [RT, BBCBreaking, UK, government, signs, Paris...  \n",
       "12676  [RT, CLIMATECHANGE, 8, Alexandra, Cousteau, on...  \n",
       "\n",
       "[15816 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "def tokenize(df):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    df['tokens'] = df['message_clean'].apply(tokenizer.tokenize)\n",
    "    return df\n",
    "\n",
    "tokenize(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8dbe356-b0a5-4a8b-b88e-98414bafcada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will supp...</td>\n",
       "      <td>[RT, ubcforestry, Funding, from, GenomeBC, wil...</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely gr...</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, is, defini...</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, definitely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wan...</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, at, all, He, ...</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about th...</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, you, forgot, a...</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half...</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing...</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "11729          1  RT @ubcforestry: Funding from @GenomeBC will s...   977844   \n",
       "8308           1  @YadiMoIina gag orders? Sure. He's definitely ...   441956   \n",
       "7159           1  RT @pattonoswalt: Not ominous at all! (He also...   978938   \n",
       "5644           1  RT @MelissaJPeltier: In case you forgot about ...   587737   \n",
       "6732           1  RT @SethMacFarlane: HRC proposes installing ha...   804767   \n",
       "\n",
       "                                  message_encoded_emojis  \\\n",
       "11729  RT @ubcforestry: Funding from @GenomeBC will s...   \n",
       "8308   @YadiMoIina gag orders? Sure. He's definitely ...   \n",
       "7159   RT @pattonoswalt: Not ominous at all! (He also...   \n",
       "5644   RT @MelissaJPeltier: In case you forgot about ...   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing ha...   \n",
       "\n",
       "                                           message_clean  \\\n",
       "11729  RT ubcforestry Funding from GenomeBC will supp...   \n",
       "8308   YadiMoIina gag orders Sure He is definitely gr...   \n",
       "7159   RT pattonoswalt Not ominous at all He also wan...   \n",
       "5644   RT MelissaJPeltier In case you forgot about th...   \n",
       "6732   RT SethMacFarlane HRC proposes installing half...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "11729  [RT, ubcforestry, Funding, from, GenomeBC, wil...   \n",
       "8308   [YadiMoIina, gag, orders, Sure, He, is, defini...   \n",
       "7159   [RT, pattonoswalt, Not, ominous, at, all, He, ...   \n",
       "5644   [RT, MelissaJPeltier, In, case, you, forgot, a...   \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing...   \n",
       "\n",
       "                                tokens_without_stopwords  \n",
       "11729  [RT, ubcforestry, Funding, GenomeBC, support, ...  \n",
       "8308   [YadiMoIina, gag, orders, Sure, He, definitely...  \n",
       "7159   [RT, pattonoswalt, Not, ominous, He, also, wan...  \n",
       "5644   [RT, MelissaJPeltier, In, case, forgot, Chines...  \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "def remove_stop_words(tokens):\n",
    "    return [t for t in tokens if t not in stopwords.words('english')]\n",
    "\n",
    "df_train['tokens_without_stopwords'] = df_train['tokens'].apply(remove_stop_words)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18b54f55-5c16-4987-b356-db7e6fdd6764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message_encoded_emojis</th>\n",
       "      <th>message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_without_stopwords</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11729</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>977844</td>\n",
       "      <td>RT @ubcforestry: Funding from @GenomeBC will s...</td>\n",
       "      <td>RT ubcforestry Funding from GenomeBC will supp...</td>\n",
       "      <td>[RT, ubcforestry, Funding, from, GenomeBC, wil...</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, ...</td>\n",
       "      <td>[RT, ubcforestry, Funding, GenomeBC, support, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>1</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>441956</td>\n",
       "      <td>@YadiMoIina gag orders? Sure. He's definitely ...</td>\n",
       "      <td>YadiMoIina gag orders Sure He is definitely gr...</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, is, defini...</td>\n",
       "      <td>[YadiMoIina, gag, orders, Sure, He, definitely...</td>\n",
       "      <td>[YadiMoIina, gag, order, Sure, He, definitely,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>978938</td>\n",
       "      <td>RT @pattonoswalt: Not ominous at all! (He also...</td>\n",
       "      <td>RT pattonoswalt Not ominous at all He also wan...</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, at, all, He, ...</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, wan...</td>\n",
       "      <td>[RT, pattonoswalt, Not, ominous, He, also, wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>587737</td>\n",
       "      <td>RT @MelissaJPeltier: In case you forgot about ...</td>\n",
       "      <td>RT MelissaJPeltier In case you forgot about th...</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, you, forgot, a...</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chines...</td>\n",
       "      <td>[RT, MelissaJPeltier, In, case, forgot, Chines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>804767</td>\n",
       "      <td>RT @SethMacFarlane: HRC proposes installing ha...</td>\n",
       "      <td>RT SethMacFarlane HRC proposes installing half...</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing...</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing...</td>\n",
       "      <td>[RT, SethMacFarlane, HRC, proposes, installing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "11729          1  RT @ubcforestry: Funding from @GenomeBC will s...   977844   \n",
       "8308           1  @YadiMoIina gag orders? Sure. He's definitely ...   441956   \n",
       "7159           1  RT @pattonoswalt: Not ominous at all! (He also...   978938   \n",
       "5644           1  RT @MelissaJPeltier: In case you forgot about ...   587737   \n",
       "6732           1  RT @SethMacFarlane: HRC proposes installing ha...   804767   \n",
       "\n",
       "                                  message_encoded_emojis  \\\n",
       "11729  RT @ubcforestry: Funding from @GenomeBC will s...   \n",
       "8308   @YadiMoIina gag orders? Sure. He's definitely ...   \n",
       "7159   RT @pattonoswalt: Not ominous at all! (He also...   \n",
       "5644   RT @MelissaJPeltier: In case you forgot about ...   \n",
       "6732   RT @SethMacFarlane: HRC proposes installing ha...   \n",
       "\n",
       "                                           message_clean  \\\n",
       "11729  RT ubcforestry Funding from GenomeBC will supp...   \n",
       "8308   YadiMoIina gag orders Sure He is definitely gr...   \n",
       "7159   RT pattonoswalt Not ominous at all He also wan...   \n",
       "5644   RT MelissaJPeltier In case you forgot about th...   \n",
       "6732   RT SethMacFarlane HRC proposes installing half...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "11729  [RT, ubcforestry, Funding, from, GenomeBC, wil...   \n",
       "8308   [YadiMoIina, gag, orders, Sure, He, is, defini...   \n",
       "7159   [RT, pattonoswalt, Not, ominous, at, all, He, ...   \n",
       "5644   [RT, MelissaJPeltier, In, case, you, forgot, a...   \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing...   \n",
       "\n",
       "                                tokens_without_stopwords  \\\n",
       "11729  [RT, ubcforestry, Funding, GenomeBC, support, ...   \n",
       "8308   [YadiMoIina, gag, orders, Sure, He, definitely...   \n",
       "7159   [RT, pattonoswalt, Not, ominous, He, also, wan...   \n",
       "5644   [RT, MelissaJPeltier, In, case, forgot, Chines...   \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing...   \n",
       "\n",
       "                                                   lemma  \n",
       "11729  [RT, ubcforestry, Funding, GenomeBC, support, ...  \n",
       "8308   [YadiMoIina, gag, order, Sure, He, definitely,...  \n",
       "7159   [RT, pattonoswalt, Not, ominous, He, also, wan...  \n",
       "5644   [RT, MelissaJPeltier, In, case, forgot, Chines...  \n",
       "6732   [RT, SethMacFarlane, HRC, proposes, installing...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "def lemmatize(words, lemmatizer):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_train['lemma'] = df_train['tokens_without_stopwords'].apply(lemmatize, args=(lemmatizer, ))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b0375-22d2-417c-9696-1c1779ef096c",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "### 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f14cbb6-bc2e-4b8c-a950-99c82278c463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert into Bag Of Words\n",
    "def vectorize(df, max_df, min_df, ngram_range, max_features):\n",
    "    # Flatten the list of lists into a single list of strings\n",
    "    df['flattened_lemma'] = df['lemma'].apply(lambda word_list: ' '.join(word_list))\n",
    "    # Create and fit the CountVectorizer\n",
    "    vect = CountVectorizer(lowercase=True, max_df=max_df, min_df=min_df, ngram_range=ngram_range, max_features=max_features)\n",
    "    vect.fit(df['flattened_lemma'])\n",
    "    X = vect.transform(df['flattened_lemma'])\n",
    "    bag_of_words = pd.DataFrame(X.toarray(), columns=vect.get_feature_names_out())\n",
    "    # Merge original dataset with Bag Of Words\n",
    "    bag_of_words.reset_index(drop=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    vectorized_df = pd.concat([bag_of_words, df],axis=1)\n",
    "    return vectorized_df\n",
    "    \n",
    "df_train = vectorize(df_train, MAX_DF, MIN_DF, NGRAM_RANGE, MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6b34223-0ec9-4cc2-9db0-30d3a03e2e8d",
   "metadata": {},
   "source": [
    "grouped = df_train.groupby('sentiment').sum()\n",
    "top_n = 10\n",
    "top_words_per_class = {}\n",
    "for class_name, row in grouped.iterrows():\n",
    "    top_words = row.sort_values(ascending=False)[:top_n]\n",
    "    top_words_per_class[class_name] = top_words\n",
    "\n",
    "# Create bar plots for top 10 words per class\n",
    "for class_name, top_words in top_words_per_class.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_words.plot(kind='bar', color='skyblue')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Top {top_n} Words in {class_name}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f347f-2108-4c7e-a05f-56d7aeb03310",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "### 6. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1eb29688-0b6a-40c7-a11f-174eb1de1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data\n",
    "def split_train_test(df):\n",
    "    X = df.copy()\n",
    "    y = X.sentiment\n",
    "    columns_to_drop = X.select_dtypes(include=['object']).columns\n",
    "    columns_to_drop = list(columns_to_drop) + ['tweetid', 'sentiment']\n",
    "    X.drop(columns=columns_to_drop,inplace=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.values, y.values)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_train_test(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b615264-745c-4d5e-aeb1-5566eb6df8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the classifiers\n",
    "names = [\n",
    "         #'Logistic Regression', \n",
    "         #'Nearest Neighbors'#,\n",
    "         #'Linear SVM',\n",
    "         'RBF SVM'#,\n",
    "         #'Decision Tree',\n",
    "         #'Random Forest',\n",
    "         #'AdaBoost'\n",
    "         ]\n",
    "\n",
    "classifiers = [\n",
    "               #LogisticRegression(max_iter=1000),\n",
    "               #KNeighborsClassifier(1)#,\n",
    "               #SVC(kernel=\"linear\", C=0.025),\n",
    "               SVC(gamma=1, C=1)#,\n",
    "               #DecisionTreeClassifier(max_depth=5),\n",
    "               #RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "               #AdaBoostClassifier()\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56e167-6788-4219-a6e4-e75a5054cdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RBF SVM model...\n"
     ]
    }
   ],
   "source": [
    "# Train all the models\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "\n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf\n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)\n",
    "\n",
    "print ('... All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad4ef0-96f4-4df5-962b-37e75a29ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('F1 Train', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c6f3f-24cf-47e4-a394-5277e5bbfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "results.sort_values('F1 Train', ascending=False, inplace=True)\n",
    "results.plot(y=['F1 Test'], kind='bar', ax=ax[0], xlim=[0,1.1], ylim=[0.05,0.99])\n",
    "results.plot(y='Train Time', kind='bar', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b66a1c-fbd6-42cd-b6aa-71dc8abe7bfd",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "### 7. Model performance evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfb44e66-46de-404b-9598-014cf6362ac5",
   "metadata": {},
   "source": [
    "# Use K-Fold cross validation\n",
    "cv = []\n",
    "for name, model in models.items():\n",
    "    print ()\n",
    "    print(name)\n",
    "    scores = cross_val_score(model, X=X.values, y=y.values, cv=10)\n",
    "    print(\"Accuracy: {:0.2f} (+/- {:0.4f})\".format(scores.mean(), scores.std()))\n",
    "    cv.append([name, scores.mean(), scores.std() ])\n",
    "\n",
    "cv = pd.DataFrame(cv, columns=['Model', 'CV_Mean', 'CV_Std_Dev'])\n",
    "cv.set_index('Model', inplace=True)\n",
    "\n",
    "cv.plot(y='CV_Mean', yerr='CV_Std_Dev',kind='bar', ylim=[0.65, 0.85])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f0187e0-3b1b-42dd-9cac-afefc09b9457",
   "metadata": {},
   "source": [
    "# GridSearchCV\n",
    "# Do for KNN and for RBF SVM\n",
    "\n",
    "ks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in ks:\n",
    "    print('Fitting KNN model with k = {:d}'.format(k))\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    run_time = %timeit -q -o knn.fit(X_train, y_train)\n",
    "\n",
    "    # predicting\n",
    "    y_pred = knn.predict(X_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "\n",
    "    # scoring\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "    # save the results \n",
    "    results.append([k, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "results = pd.DataFrame(results, columns=['KNN', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('KNN', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fb1ba-4f52-4892-86b3-bc2e00d5a6b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8060330-bd6a-4e1c-b2d5-1c18930dcfae",
   "metadata": {},
   "source": [
    "<a id=\"eight\"></a>\n",
    "### 8. Model analysis and conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7774055e-780a-45c9-a038-9d519b4cf049",
   "metadata": {},
   "source": [
    "# GridSearchCV for SVM (RBF)\n",
    "param_grid = {'kernel': ['rbf'],\n",
    "              'gamma': (0.5,1,2),\n",
    "              'C': (0.5,0.75,1.0)}\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, param_grid, scoring='f1_macro', cv=2)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d182252c-6761-4314-90f0-5c24382d55a6",
   "metadata": {},
   "source": [
    "svm = SVC(kernel='rbf', gamma=1.0, C=1.0)\n",
    "clf = svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "print ('... scoring')\n",
    "accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "\n",
    "f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print(f'f1-test: {f1_test}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a676ad-8a98-4887-99fd-c452a912e400",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# See how it performs with 500 features\n",
    "\n",
    "df_train2 = pd.read_csv('G:/My Drive/Professionele ontwikkeling/Data Science/Explore Data Science Course/Sprint 6_Advanced Classification/Predict/advanced-classification-predict/data/train.csv')\n",
    "remove_noise(df_train2)\n",
    "process_emoticons(df_train2)\n",
    "df_train2['message_clean'] = df_train2['message_encoded_emojis'].apply(remove_punctuation)\n",
    "tokenize(df_train2)\n",
    "df_train2['tokens_without_stopwords'] = df_train2['tokens'].apply(remove_stop_words)\n",
    "df_train2['lemma'] = df_train2['tokens_without_stopwords'].apply(lemmatize, args=(lemmatizer, ))\n",
    "df_train2 = vectorize(df_train2, MAX_DF, MIN_DF, NGRAM_RANGE, 500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_train_test(df_train2)\n",
    "\n",
    "\n",
    "names = [\n",
    "         #'Logistic Regression', \n",
    "         #'Nearest Neighbors'#,\n",
    "         #'Linear SVM',\n",
    "         'RBF SVM'#,\n",
    "         #'Decision Tree',\n",
    "         #'Random Forest',\n",
    "         #'AdaBoost'\n",
    "         ]\n",
    "\n",
    "classifiers = [\n",
    "               #LogisticRegression(max_iter=1000),\n",
    "               #KNeighborsClassifier(1)#,\n",
    "               #SVC(kernel=\"linear\", C=0.025),\n",
    "               SVC(gamma=1, C=1)#,\n",
    "               #DecisionTreeClassifier(max_depth=5),\n",
    "               #RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "               #AdaBoostClassifier()\n",
    "               ]\n",
    "\n",
    "# Train all the models\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='weighted')\n",
    "\n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='weighted')\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf\n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)\n",
    "\n",
    "print ('... All done!')\n",
    "print(results.sort_values('F1 Train', ascending=False))\n",
    "\n",
    "# Use K-Fold cross validation\n",
    "\n",
    "\"\"\"\n",
    "cv = []\n",
    "for name, model in models.items():\n",
    "    print ()\n",
    "    print(name)\n",
    "    scores = cross_val_score(model, X=X.values, y=y.values, cv=10)\n",
    "    print(\"Accuracy: {:0.2f} (+/- {:0.4f})\".format(scores.mean(), scores.std()))\n",
    "    cv.append([name, scores.mean(), scores.std() ])\n",
    "\n",
    "cv = pd.DataFrame(cv, columns=['Model', 'CV_Mean', 'CV_Std_Dev'])\n",
    "cv.set_index('Model', inplace=True)\n",
    "\n",
    "cv.plot(y='CV_Mean', yerr='CV_Std_Dev',kind='bar', ylim=[0.25, 0.99])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd06b96-392c-483e-82e2-ceee9107be65",
   "metadata": {},
   "source": [
    "## Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ab399-1dfe-41ba-95bb-7704cbbb1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('G:/My Drive/Professionele ontwikkeling/Data Science/Explore Data Science Course/Sprint 6_Advanced Classification/Predict/advanced-classification-predict/data/test_with_no_labels.csv')\n",
    "remove_noise(df_test)\n",
    "process_emoticons(df_test)\n",
    "df_test['message_clean'] = df_test['message_encoded_emojis'].apply(remove_punctuation)\n",
    "tokenize(df_test)\n",
    "df_test['tokens_without_stopwords'] = df_test['tokens'].apply(remove_stop_words)\n",
    "df_test['lemma'] = df_test['tokens_without_stopwords'].apply(lemmatize, args=(lemmatizer, ))\n",
    "df_test = vectorize(df_test, MAX_DF, MIN_DF, NGRAM_RANGE, MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd6ac2-defc-44af-b293-57c7faa09c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "columns_to_drop = df_test.select_dtypes(include=['object']).columns\n",
    "df_test.drop(columns=columns_to_drop,inplace=True)\n",
    "X = df_test.copy()\n",
    "X = X.drop(columns='tweetid')\n",
    "trained_model = models['RBF SVM']\n",
    "y_pred = trained_model.predict(X.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
